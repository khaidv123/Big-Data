{"cells":[{"cell_type":"code","source":["HADOOP_URL = \"https://dlcdn.apache.org/hadoop/common/stable/hadoop-3.4.0.tar.gz\"\n","\n","import requests\n","import os\n","import tarfile\n","\n","def download_and_extract_targz(url):\n","    response = requests.get(url)\n","    filename = url.rsplit('/', 1)[-1]\n","    HADOOP_HOME = filename[:-7]\n","    # set HADOOP_HOME environment variable\n","    os.environ['HADOOP_HOME'] = HADOOP_HOME\n","    if os.path.isdir(HADOOP_HOME):\n","      print(\"Not downloading, Hadoop folder {} already exists\".format(HADOOP_HOME))\n","      return\n","    if response.status_code == 200:\n","        with open(filename, 'wb') as file:\n","            file.write(response.content)\n","        with tarfile.open(filename, 'r:gz') as tar_ref:\n","            extract_path = tar_ref.extractall(path='.')\n","            # Get the names of all members (files and directories) in the archive\n","            all_members = tar_ref.getnames()\n","            # If there is a top-level directory, get its name\n","            if all_members:\n","              top_level_directory = all_members[0]\n","              print(f\"ZIP file downloaded and extracted successfully. Contents saved at: {top_level_directory}\")\n","    else:\n","        print(f\"Failed to download ZIP file. Status code: {response.status_code}\")\n","\n","\n","download_and_extract_targz(HADOOP_URL)\n","# HADOOP_HOME was set earlier when downloading Hadoop distribution\n","print(\"HADOOP_HOME is {}\".format(os.environ['HADOOP_HOME']))\n","\n","os.environ['PATH'] = ':'.join([os.path.join(os.environ['HADOOP_HOME'], 'bin'), os.environ['PATH']])\n","print(\"PATH is {}\".format(os.environ['PATH']))\n","import shutil\n","\n","# set variable JAVA_HOME (install Java if necessary)\n","def is_java_installed():\n","    os.environ['JAVA_HOME'] = os.path.realpath(shutil.which(\"java\")).split('/bin')[0]\n","    return os.environ['JAVA_HOME']\n","\n","def install_java():\n","    # Uncomment and modify the desired version\n","    # java_version= 'openjdk-11-jre-headless'\n","    # java_version= 'default-jre'\n","    # java_version= 'openjdk-17-jre-headless'\n","    # java_version= 'openjdk-18-jre-headless'\n","    java_version= 'openjdk-19-jre-headless'\n","\n","    print(f\"Java not found. Installing {java_version} ... (this might take a while)\")\n","    try:\n","        cmd = f\"apt install -y {java_version}\"\n","        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n","        stdout_result = subprocess_output.stdout\n","        # Process the results as needed\n","        print(\"Done installing Java {}\".format(java_version))\n","        os.environ['JAVA_HOME'] = os.path.realpath(shutil.which(\"java\")).split('/bin')[0]\n","        print(\"JAVA_HOME is {}\".format(os.environ['JAVA_HOME']))\n","    except subprocess.CalledProcessError as e:\n","        # Handle the error if the command returns a non-zero exit code\n","        print(\"Command failed with return code {}\".format(e.returncode))\n","        print(\"stdout: {}\".format(e.stdout))\n","\n","# Install Java if not available\n","if is_java_installed():\n","    print(\"Java is already installed: {}\".format(os.environ['JAVA_HOME']))\n","else:\n","    print(\"Installing Java\")\n","    install_java()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cbjcsXoeIUa","outputId":"cce795e2-124b-443b-a98e-13f35a440ead","executionInfo":{"status":"ok","timestamp":1715009888297,"user_tz":-420,"elapsed":37889,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ZIP file downloaded and extracted successfully. Contents saved at: hadoop-3.4.0\n","HADOOP_HOME is hadoop-3.4.0\n","PATH is hadoop-3.4.0/bin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n","Java is already installed: /usr/lib/jvm/java-11-openjdk-amd64\n"]}]},{"cell_type":"markdown","metadata":{"id":"y59n_nBOd87z"},"source":["# Simple distributed wordcount with MapReduce"]},{"cell_type":"markdown","metadata":{"id":"LTb_j70rd870"},"source":["Check that file `file.txt` exists, view size."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2hw8tRYd871","outputId":"9b88a5aa-a142-4ddc-eda8-0f50731ad2ae","executionInfo":{"status":"ok","timestamp":1715009888298,"user_tz":-420,"elapsed":11,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access 'file.txt': No such file or directory\n"]}],"source":["!ls -hal file.txt"]},{"cell_type":"markdown","metadata":{"id":"kRc6B38Rd871"},"source":["Copy file to HDFS"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hjsFsWCgd871","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715009891780,"user_tz":-420,"elapsed":3487,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}},"outputId":"8d6e030c-a5f2-444a-cce3-4add8c7fc719"},"outputs":[{"output_type":"stream","name":"stdout","text":["put: `file.txt': No such file or directory\n"]}],"source":["!hdfs dfs -put -f file.txt"]},{"cell_type":"markdown","metadata":{"id":"Onx9QlBXd872"},"source":["Erase `result` folder."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"elm88xjPd872","executionInfo":{"status":"ok","timestamp":1715009893808,"user_tz":-420,"elapsed":2033,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}}},"outputs":[],"source":["!hdfs dfs -rm -R result 2>/dev/null"]},{"cell_type":"markdown","metadata":{"id":"tepprHw9d872"},"source":["Run the bash wordcount command `wc` in parallel on the distributed file."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Azfq6JmNd872","outputId":"a137c415-d92d-4a4b-a92f-2c4a4175f121","executionInfo":{"status":"ok","timestamp":1715009897108,"user_tz":-420,"elapsed":3304,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-06 15:38:15,089 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-05-06 15:38:15,379 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-05-06 15:38:15,379 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","2024-05-06 15:38:15,407 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-05-06 15:38:15,746 INFO mapreduce.JobSubmitter: Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root171776672/.staging/job_local171776672_0001\n","2024-05-06 15:38:15,763 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: file:/content/file.txt\n","Streaming Command Failed!\n"]}],"source":["!mapred streaming \\\n","  -input file.txt \\\n","  -output result \\\n","  -mapper /bin/cat \\\n","  -reducer /usr/bin/wc"]},{"cell_type":"markdown","metadata":{"id":"bv8Zs3EQd872"},"source":["Check result of MapReduce job"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBt8I9wDd872","outputId":"7a9c3c02-304d-4528-9b2e-e76415019c0a","executionInfo":{"status":"ok","timestamp":1715009899090,"user_tz":-420,"elapsed":1987,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cat: `result/part*': No such file or directory\n"]}],"source":["!hdfs dfs -cat result/part*"]},{"cell_type":"markdown","metadata":{"id":"U7avjGVXd872"},"source":["Check that the word count is correct by comparing with `wc` on local host (warning: do not try with too large files)."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlDIBOzEd873","outputId":"f4a8113e-be1c-4f1e-8a38-970e80887d8c","executionInfo":{"status":"ok","timestamp":1715009899463,"user_tz":-420,"elapsed":377,"user":{"displayName":"5886 Đặng Văn Khải","userId":"00827885371675823732"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["wc: file.txt: No such file or directory\n"]}],"source":["!wc file.txt"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}